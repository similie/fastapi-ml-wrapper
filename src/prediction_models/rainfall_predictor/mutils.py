from os import path, listdir
## Imports for plotting
import matplotlib.pyplot as plt
import matplotlib
import matplotlib.ticker as ticker
import seaborn as sns
from time import time

from layers.model import Forecaster, Autoencoder
import pytorch_lightning as pl

import torch
import pandas as pd

from AllWeatherConfig import getAllWeatherConfig
from AllWeatherCubeResponse import AllWeatherCubeQueryResponse
from AllWeatherCubeResponse import cleanCubeNameFromResponseKeys

def forecaster_from_pretrained(checkpoint_path: str) -> pl.LightningModule:
    model = Forecaster.load_from_checkpoint(checkpoint_path)
    model.freeze()
    return model

def autoencoder_from_pretrained(checkpoint_path: str) -> pl.LightningModule:
    model = Autoencoder.load_from_checkpoint(checkpoint_path)
    model.freeze()
    return model

def serialise_ml_data():
    jsonData = loadJsonFixture()
    cubeName = getAllWeatherConfig().cube_name
    cleanedJson = cleanCubeNameFromResponseKeys(jsonData)
    jsonData = json.loads(cleanedJson)
    model = AllWeatherCubeQueryResponse.model_validate(jsonData)
    return model
    
def loadJsonFixture():
    '''
    load the sample Json file to the Cube query resonse model format.
    '''
    p = path.join('/home/leigh/Code/ekoh/similie/',
                    'test',
                    'fixtures', 
                    'all_weather_cube_query_response.json')
    with open(p, 'r') as file:
        jsonData = json.load(file)
        return json.dumps(jsonData)

def get_checkpoint_filepath(model_prefix: str = "FC",
                            latent_dim: int = 128, 
                            checkpoint_path: str ="results"):
    prefixes = ["FC", "AE"]
    if model_prefix not in prefixes:
        raise ValueError("Invalid prefix. Expected one of: %s" % prefixes)
    project_root = path.dirname(__file__)
    filename = listdir(path.join(project_root, 
        checkpoint_path,
        f"{model_prefix}_model{latent_dim}",
        "version_0/checkpoints/"))[0]
    
    return path.join(project_root, 
        checkpoint_path,
        f"{model_prefix}_model{latent_dim}",
        "version_0/checkpoints",
        filename)

def get_pretrain_filepath(model_prefix: str = "FC",
                            latent_dim: int = 64, 
                            pretrain_path: str ="pretrained_checkpoints"):
    prefixes = ["FC", "AE"]
    if model_prefix not in prefixes:
        raise ValueError("Invalid prefix. Expected one of: %s" % prefixes)
    project_root = path.dirname(__file__)
    return path.join(project_root, 
        pretrain_path,
        f"{model_prefix}_model{latent_dim}",
        "pretrained.ckpt")

def plot_loss(metrics_path: str):
    df = pd.read_csv(check_pt_path)
    sns.set_style('darkgrid')
    sns.set(rc={'figure.figsize':(14,8)})
    ax = sns.lineplot(data=df,
                      x = df.step % 1000,
                      y = df.iloc[:,2],
                      legend='full',
                      lw=3)
    plt.savefig('results/' + 'trainloss.pdf')

def plot_predictions(preds: dict, target: str = "precipitation"):
    """
        Plot predictions generated by models
        for all the stations. Saves plot as 
        pdf in the results file.
    """
    sns.set_style('darkgrid')
    sns.set(rc={'figure.figsize':(14,8)})
    df_list = []
    for s, _df in preds.items():
        _df['station'] = s
        df_list.append(_df)
    concat_df = pd.concat(df_list).sort_index()
    ax = sns.lineplot(data=concat_df, 
                      x = concat_df.index.strftime('%B %d, %r'), 
                      y = concat_df[target],
                      hue=concat_df['station'], palette='viridis',
                      legend='full', 
                      lw=3)
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.set(ylim=(-.1, 10))
    plt.legend(bbox_to_anchor=(1, 1))
    plt.xticks(rotation=45)
    plt.ylabel('rainfall (mm)')
    plt.xlabel('month-day-hour')
    filename = f"./results/predictions{int(time())}.pdf"
    plt.savefig(filename)
    # plt.show()
    

def reconstruction_predictions(model, input_data):
    """ 
        Not used as of yet. Look at generate_predictions
        in predict.py TODO add this to use the AE as a 
        data imputer at some stage.
        Inputs: 
            - trained AE model
            - input data (scaled tensors)        
        Reconstruct timeseries - shifted by 12 hours
        Can feed the predictions back into the model
        to get 24 hours, etc...
    """
    model.eval()
    with torch.no_grad():
        reconst_timeseries = model(input_data.to(model.device))
    reconst_timeseries = reconst_timeseries.cpu()
    return reconst_timeseries.numpy()

